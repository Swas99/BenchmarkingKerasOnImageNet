{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark Keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4_I9FkrRrqsR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIb-I_Y-4uWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "450a42f5-8ba5-446e-d4ea-d71b221d33e2"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lKt0znjDr-R8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUps3mMo0wLW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip show keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBi4Dc5isFI4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction Models"
      ]
    },
    {
      "metadata": {
        "id": "k6nrvZD5sJCR",
        "colab_type": "code",
        "outputId": "84fb9544-00c4-4a6f-d1aa-c88267611cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import vgg16, vgg19, resnet50, inception_v3, inception_resnet_v2, xception, densenet, nasnet\n",
        "\n",
        "# #224x224 input models\n",
        "# #Load the VGG model\n",
        "vgg16_model = vgg16.VGG16(weights='imagenet')\n",
        "\n",
        "# #Load the VGG model\n",
        "vgg19_model = vgg19.VGG19(weights='imagenet')\n",
        "\n",
        "# #Load the VGG model\n",
        "resnet50_model = resnet50.ResNet50(weights='imagenet')\n",
        "\n",
        "# #Load the VGG model\n",
        "densenet121_model = densenet.DenseNet121(weights='imagenet')\n",
        "\n",
        "# #Load the VGG model\n",
        "densenet169_model = densenet.DenseNet169(weights='imagenet')\n",
        "\n",
        "# #Load the VGG model\n",
        "densenet201_model = densenet.DenseNet201(weights='imagenet')\n",
        "\n",
        "##----------------------------------------##\n",
        "\n",
        "#299x299 input models\n",
        "#Load the Inception_V3 model \n",
        "inceptionv3_model = inception_v3.InceptionV3(weights='imagenet') \n",
        "\n",
        "#Load the InceptionResNetV2 model\n",
        "inception_resnet_v2_model = inception_resnet_v2.InceptionResNetV2(weights='imagenet')\n",
        "\n",
        "#Load the Xception model\n",
        "xception_model = xception.Xception(weights='imagenet')\n",
        "\n",
        "##----------------------------------------##\n",
        "\n",
        "#Need 331x331\n",
        "#Load the NASNet model \n",
        "nasnet_model = nasnet.NASNetLarge(weights='imagenet') \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 6s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102858752/102853048 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
            "33193984/33188688 [==============================] - 0s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels.h5\n",
            "58548224/58541896 [==============================] - 2s 0us/step\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels.h5\n",
            "82526208/82524592 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 4s 0us/step\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91889664/91884032 [==============================] - 1s 0us/step\n",
            "Downloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-large.h5\n",
            "359751680/359748576 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Anr8WhoEwtn4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Labels"
      ]
    },
    {
      "metadata": {
        "id": "J6PZHHyxxQa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtKRartewxfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val = np.load(\"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/y_val.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GOkTMkfxFeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Do this once!\n",
        "#Make rows in y_val a multiple of 3500; coz we have 3500 rows\n",
        "# y_val = np.append (y_val, np.zeros(2500)) \n",
        "\n",
        "y_val = y_val.reshape((15, 3500 ))\n",
        "y_val_one_hot = to_categorical(y_val[0], 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QmOYi9Wspb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keras_idx_to_name = {}\n",
        "f = open(\"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/synset_words.txt\",\"r\")\n",
        "idx = 0\n",
        "for line in f:\n",
        "    parts = line.split(\" \")\n",
        "    keras_idx_to_name[idx] = \" \".join(parts[1:])\n",
        "    idx += 1\n",
        "f.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJWBN55XyWEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BenchMarking Logic"
      ]
    },
    {
      "metadata": {
        "id": "E8DCUssEDekM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def top_k_accuracy(y_true, y_pred, k=1):\n",
        "    '''From: https://github.com/chainer/chainer/issues/606\n",
        "    \n",
        "    Expects both y_true and y_pred to be one-hot encoded.\n",
        "    '''\n",
        "    argsorted_y = np.argsort(y_pred)[:,-k:]\n",
        "    return np.any(argsorted_y.T == y_true.argmax(axis=1), axis=0).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXhGrgu9bEtq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def savePredictions(m_i, val):\n",
        "  base_path = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetBenchMarkingResults/Predictions/\"\n",
        "  np.save(base_path + str(m_i) + \".npy\", val)\n",
        "  \n",
        "def loadPredictions(m_i):\n",
        "  base_path = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetBenchMarkingResults/Predictions/\"\n",
        "  return np.load(base_path + str(m_i) + \".npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWBQHB7ayZ7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocessData(x_val, mClass):\n",
        "  if mClass == 0:\n",
        "    x_val = vgg16.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 1:\n",
        "    x_val = vgg19.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 2:\n",
        "    x_val = resnet50.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 3:\n",
        "    x_val = densenet.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 4:\n",
        "    x_val = densenet.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 5:\n",
        "    x_val = densenet.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 6:\n",
        "    x_val = inception_v3.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 7:\n",
        "    x_val = inception_resnet_v2.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 8:\n",
        "    x_val = xception.preprocess_input(x_val) # converted to BGR\n",
        "  elif mClass == 9:\n",
        "    x_val = nasnet.preprocess_input(x_val) # converted to BGR\n",
        "  return x_val\n",
        "\n",
        "def savePredictions(predictionModels, imageRes = \"224x224\", base = 0):\n",
        "  \n",
        "  # imageRes = \"224x224\"\n",
        "  # imageRes = \"299x299\"\n",
        "  # imageRes = \"331x331\"\n",
        "\n",
        "  X = [\"\" for x in range(7)]\n",
        "  X[0] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_1.npy\"\n",
        "  X[1] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_2.npy\"\n",
        "  X[2] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_3.npy\"\n",
        "  X[3] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_4.npy\"\n",
        "  X[4] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_5.npy\"\n",
        "  X[5] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_6.npy\"\n",
        "  X[6] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_7.npy\"\n",
        "  #X[7] = \"/content/drive/My Drive/MS_CS_DS/Sem2/AI/ImageNetValidationMetaDeta/\" + imageRes + \"/x_val_8.npy\"\n",
        "  \n",
        "\n",
        "  totalModels = len(predictionModels)\n",
        "  \n",
        "  for i in range(0, len(X)):\n",
        "    x_val = np.load(X[i]) # loaded as RGB\n",
        "#     for m_i in range(0, totalModels):\n",
        "#       model = predictionModels[m_i]\n",
        "#       x_val = preprocessData(x_val, m_i+base)\n",
        "#       savePredictions(m_i+base, model.predict(x_val, verbose=1))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKof3hUAbD4Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def processPredictions(totalModels):\n",
        "  \n",
        "  Y_PREDS = np.zeros(totalModels*7*500)\n",
        "  Y_PREDS = Y_PREDS.reshape(totalModels, 7, 500)\n",
        "\n",
        "  for i in range(0, totalModels):\n",
        "    Y_PREDS[i] = loadPredictions(i)\n",
        "    \n",
        "  for m_i in range(0, totalModels):\n",
        "    Y_PREDS[m_i].reshape(1, 3500)\n",
        "      \n",
        "  K = 10\n",
        "  topKPredictions = np.arrange(K*totalModels).reshape(totalModels,K)\n",
        "  \n",
        "  for k in range(1,K+1):\n",
        "    for m_i in range(0, totalModels):\n",
        "      topKPredictions[m_i, k-1] = top_k_accuracy(y_val_one_hot, Y_PREDS[m_i], k)\n",
        "    \n",
        "  return topKPredictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9e3g7q1VJfq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41WNlsCItDGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Run the tests"
      ]
    },
    {
      "metadata": {
        "id": "Uw8p394qWpjV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 224x224 input models"
      ]
    },
    {
      "metadata": {
        "id": "b5u2cRPBtBBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imageRes = \"224x224\"\n",
        "\n",
        "models = []\n",
        "# models.append(vgg16_model)\n",
        "models.append(vgg19_model)\n",
        "models.append(resnet50_model)\n",
        "models.append(densenet121_model)\n",
        "models.append(densenet169_model)\n",
        "models.append(densenet201_model)\n",
        " \n",
        "\n",
        "savePredictions(predictionModels = models, imageRes = imageRes, base = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDkoWL-4WzA_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 299x299 input models"
      ]
    },
    {
      "metadata": {
        "id": "ffUK9RuiW5IS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imageRes = \"299x299\"\n",
        "\n",
        "models = []\n",
        "models.append(inceptionv3_model)\n",
        "models.append(inception_resnet_v2_model)\n",
        "models.append(xception_model)\n",
        "\n",
        "savePredictions(predictionModels = models, imageRes = imageRes, base = 6)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBzr4cm8W0yI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 331x331 input models"
      ]
    },
    {
      "metadata": {
        "id": "fW2XB0Z8W6ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imageRes = \"331x331\"\n",
        "\n",
        "models = []\n",
        "models.append(nasnet_model)\n",
        "\n",
        "savePredictions(predictionModels = models, imageRes = imageRes, base = 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMQM0WM3XbNT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Results and Analysis"
      ]
    },
    {
      "metadata": {
        "id": "lrMQQduvsdkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelName = [\"\" for x in range(10)]\n",
        "modelName = { \"VGG16\", \"VGG19\", \"RESNET50\", \"DENSENET121\", \"DENSENET169\", \"DENSENET201\", \"INCEPTIONV3\", \"INCEPTION_RESNET_V2\", \"XCEPTION\", \"NASNET\" } \n",
        "\n",
        "topKPredictions = processPredictions(10)\n",
        "\n",
        "out = \"\"\n",
        "for k in range(0, 10):\n",
        "  out = out + \"Top-\" + str(k) + \",\"\n",
        "out = out + \"\\n\"\n",
        "\n",
        "for m_i in range(0, totalModels):\n",
        "  for k in range(0, 10):\n",
        "    out = out + topKPredictions[m_i, k] + \",\"\n",
        "  out = out + \"\\n\"\n",
        "\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHT-j2yCiaZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FPhAey_TsoaT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "processed_image = densenet.preprocess_input(image_batch.copy())\n",
        " \n",
        "# get the predicted probabilities for each class\n",
        "predictions = densenet1.predict(processed_image)\n",
        "\n",
        "# print predictions\n",
        "# convert the probabilities to class labels\n",
        "# We will get top 5 predictions which is the default\n",
        "# plt.imshow(original)\n",
        "\n",
        "\n",
        "for prediction in decode_predictions(predictions)[0]:\n",
        "  print(prediction[1], prediction[2])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}